p8105_hw2_zj2379
================
Zheshu Jiang
2023-10-02

\##Problem 1 First, clean the data in pols-month.csv. Use separate() to
break up the variable mon into integer variables year, month, and day;
replace month number with month name; create a president variable taking
values gop and dem, and remove prez_dem and prez_gop; and remove the day
variable.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```

Clean the data in pols-month.csv

``` r
pols=
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>%
  janitor::clean_names() %>% 
  separate(mon,into=c("year","month","day"),sep="-") %>% 
  mutate_at(vars(year, month, day), as.numeric) %>% 
  mutate(month=recode(month, '01'="January" , '02'="February",'03'="March",'04'="April","05"="May","06"="June","07"="July","08"="August","09"="Septemer","10"="October","11"="November","12"="December")) %>% 
   mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) %>% 
  select(year, month, everything(), -day, -starts_with("prez"))
```

    ## Joining with `by = join_by(month)`

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, close) 
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
   rename(year = Year) %>% 
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) %>% 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
data_538 = 
  left_join(pols, snp)|>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

## problem 2

``` r
library(readxl)
```

``` r
mrtrashweel=
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(if_any(everything(), ~ !is.na(.)))%>%
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  mutate_at(vars(year), as.numeric) %>% 
  drop_na(dumpster) %>% 
  add_column(type = "Mr. Trash") %>%
  select(-x15,-x16)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mrtrashweel
```

    ## # A tibble: 584 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>, type <chr>

``` r
gwynndatrashweel=
   read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Gwynnda Trash Wheel") %>% 
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  drop_na(dumpster) %>% 
  add_column(type = "Gwynnda Trash") 
```

``` r
professortrashweel=
   read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Professor Trash Wheel") %>% 
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  drop_na(dumpster) %>% 
  add_column(type = "Professor Trash") 
```

``` r
#merge three datasets
data_combine = 
  bind_rows(mrtrashweel, professortrashweel) |>
  bind_rows(x = _, y = gwynndatrashweel)
```

For each dataset, I clean the data, update the home_powered vlues, and
add a new column.

The `mrtrashweel` data has 584 obervations and 15 variables and tells us
about the weight of different types of trash for a given year from years
2014 to 2022 to power the number of homes ranging from 13 to 93.6666667
and the average number of home powered is 53.5131279.

The `professortrashweel` data has 106 obervations and 14 variables and
tells us about the weight of different types of trash for a given year
from years 2017 to 2022 to power the number of homes ranging from
10.1666667 to 62 and the average number of home powered is 34.0031447.

The `gwynndatrashweel` data has 155 obervations and 13 variables and
tells us about the weight of different types of trash for a given year
from years 2021 to 2022 to power the number of homes ranging from
12.8333333 to 69.6666667 and the average number of home powered is
48.5645161.

The `data_combine` data has 845 obervations and 15 variables and tells
us about the weight of different types of trash for a given year from
years 2014 to 2022 to power the number of homes ranging from 10.1666667
to 93.6666667 and the average number of home powered is 50.1579882.

The total weight of trash collected by Professor Trash Wheel is
216.26tons and the total number of cigarette butts collected by Gwynnda
in July of 2021 is 1.39^{4}.

## Problem 3

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
baseline=
  read_csv("./data/data_mci/MCI_baseline.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  mutate(
    sex = recode(sex, "0" = "female", "1" = "male"),
    apoe4 = recode(apoe4, "0" = "non-apoe4 carrier", "1" = "apoe4 carrier"),
    age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)
  ) |>
  filter(current_age < age_at_onset | is.na(age_at_onset)) 
```

    ## Rows: 483 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): Age at onset
    ## dbl (5): ID, Current Age, Sex, Education, apoe4
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I import the daseline dataset and clean it by removing observations
without MCI records and the first row. There were originally 483
participants, 479 of them have developed MCI. The average baseline age
is NA. 30% of women in the study are APOE4 carriers.

``` r
amyloid = read_csv("./data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(
    id = study_id,
    time_0 = baseline
    ) |>
  pivot_longer(
    time_0:time_8, 
    names_to = "timeperiod",
    values_to = "time in years elapsed"
  ) 
```

    ## Rows: 487 Columns: 6
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (5): Baseline, Time 2, Time 4, Time 6, Time 8
    ## dbl (1): Study ID
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

I import the amuloid.cvs data, remove the first row, rename two columns,
set time period from time_0 to time_8, and use pivot_longer to transpose
data from wider to longer for better visulization. The final amyloid
dataset has 2435 observations.

``` r
# Find participants unique to the "baseline" dataset
baseline_unique=anti_join(baseline,amyloid)
```

    ## Joining with `by = join_by(id)`

``` r
nrow(baseline_unique)
```

    ## [1] 8

``` r
# Find participants unique to the "amyloid" dataset
amyloid_unique=anti_join(amyloid, baseline)
```

    ## Joining with `by = join_by(id)`

``` r
nrow(amyloid_unique)
```

    ## [1] 80

``` r
# Combine the datasets, retaining only participants common to both datasets
combined_data2 <- inner_join(baseline, amyloid, by = "id")
nrow(combined_data2)
```

    ## [1] 2355

8 participants found unique to the baseline dataset and 80 participants
found unique to the amyloid dataset. 2355 appear in both datasets.
