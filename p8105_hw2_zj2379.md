p8105_hw2_zj2379
================
Zheshu Jiang
2023-10-02

\##Problem 1 First, clean the data in pols-month.csv. Use separate() to
break up the variable mon into integer variables year, month, and day;
replace month number with month name; create a president variable taking
values gop and dem, and remove prez_dem and prez_gop; and remove the day
variable.

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.3     ✔ readr     2.1.4
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.0
    ## ✔ ggplot2   3.4.3     ✔ tibble    3.2.1
    ## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0
    ## ✔ purrr     1.0.2     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```

Clean the data in pols-month.csv

``` r
pols=
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>%
  janitor::clean_names() %>% 
  separate(mon,into=c("year","month","day"),sep="-") %>% 
  mutate_at(vars(year, month, day), as.numeric) %>% 
  mutate(month=recode(month, '01'="January" , '02'="February",'03'="March",'04'="April","05"="May","06"="June","07"="July","08"="August","09"="Septemer","10"="October","11"="November","12"="December")) %>% 
   mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) %>% 
  select(year, month, everything(), -day, -starts_with("prez"))
```

    ## Joining with `by = join_by(month)`

Second, clean the data in snp.csv using a similar process to the above.
For consistency across datasets, arrange according to year and month,
and organize so that year and month are the leading columns.

``` r
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, close) 
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

Third, tidy the unemployment data so that it can be merged with the
previous datasets. This process will involve switching from “wide” to
“long” format; ensuring that key variables have the same name; and
ensuring that key variables take the same values.

``` r
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
   rename(year = Year) %>% 
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) %>% 
  select(year, month, unemployment)
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## Joining with `by = join_by(month_abb)`

Join the datasets by merging snp into pols, and merging unemployment
into the result.

``` r
data_538 = 
  left_join(pols, snp)|>
  left_join(x = _, y = unemployment)
```

    ## Joining with `by = join_by(year, month)`
    ## Joining with `by = join_by(year, month)`

## problem 2

``` r
library(readxl)
```

``` r
mrtrashweel=
  #read the Mr. Trash Wheel sheet
   read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet="Mr. Trash Wheel") %>%
  #clean the dataset and filter out missing values
  janitor::clean_names() %>%
  filter(if_any(everything(), ~ !is.na(.)))%>%
  #update the homes_powered values
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  #remove desimal points from homes_powered values
  mutate(homes_powered=trunc(homes_powered)) %>% 
  #remove some columns
  select(-x15,-x16) %>% 
  #convert year from character to numeric variable
  mutate_at(vars(year), as.numeric)
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mrtrashweel
```

    ## # A tibble: 548 × 14
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 538 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <dbl>, homes_powered <dbl>

Use a similar process to import, clean, and organize the data for
Professor Trash Wheel and Gwynnda, and combine these with the Mr. Trash
Wheel dataset to produce a single tidy dataset. To keep track of which
Trash Wheel is which, you may need to add an additional variable to all
datasets before combining.

``` r
gwynndatrashweel=
  #read the Gwynnda Trash Wheel sheet
   read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet="Gwynnda Trash Wheel") %>% 
  #clean the dataset and filter out missing values
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  #update the homes_powered values
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  #remove desimal points from homes_powered values
  mutate(homes_powered=trunc(homes_powered))

gwynndatrashweel
```

    ## # A tibble: 107 × 11
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 97 more rows
    ## # ℹ 5 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, homes_powered <dbl>

``` r
professortrashweel=
  #read the Professor Trash Wheel sheet
   read_excel("./data/202207 Trash Wheel Collection Data.xlsx", sheet="Professor Trash Wheel") %>% 
  #clean the dataset and filter out missing values
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  #update the homes_powered values
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  #remove desimal points from homes_powered values
  mutate(homes_powered=trunc(homes_powered))

professortrashweel
```

    ## # A tibble: 95 × 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 85 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, homes_powered <dbl>

``` r
#merge three datasets
data_combine = 
  left_join(mrtrashweel,professortrashweel)|>
  left_join(x = _, y = gwynndatrashweel)
```

    ## Joining with `by = join_by(dumpster, month, year, date, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## glass_bottles, grocery_bags, chip_bags, homes_powered)`
    ## Joining with `by = join_by(dumpster, month, year, date, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## homes_powered)`

``` r
data_combine
```

    ## # A tibble: 548 × 15
    ##    dumpster month  year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 May    2014 2014-05-16 00:00:00        4.31                 18
    ##  2        2 May    2014 2014-05-16 00:00:00        2.74                 13
    ##  3        3 May    2014 2014-05-16 00:00:00        3.45                 15
    ##  4        4 May    2014 2014-05-17 00:00:00        3.1                  15
    ##  5        5 May    2014 2014-05-17 00:00:00        4.06                 18
    ##  6        6 May    2014 2014-05-20 00:00:00        2.71                 13
    ##  7        7 May    2014 2014-05-21 00:00:00        1.91                  8
    ##  8        8 May    2014 2014-05-28 00:00:00        3.7                  16
    ##  9        9 June   2014 2014-06-05 00:00:00        2.52                 14
    ## 10       10 June   2014 2014-06-11 00:00:00        3.76                 18
    ## # ℹ 538 more rows
    ## # ℹ 9 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, grocery_bags <dbl>,
    ## #   chip_bags <dbl>, sports_balls <dbl>, homes_powered <dbl>,
    ## #   plastic_bags <dbl>

Write a paragraph about these data; you are encouraged to use inline R.
Be sure to note the number of observations in the resulting dataset, and
give examples of key variables. For available data, what was the total
weight of trash collected by Professor Trash Wheel? What was the total
number of cigarette butts collected by Gwynnda in July of 2021?

``` r
#create a sub-dataset from gwynndajuly only have the observations from july
gwynndajuly <- filter(gwynndatrashweel, month == "July")
#calculate the sum of igarette_butts
sum(gwynndajuly$cigarette_butts) 
```

    ## [1] 47390

The `mrtrashweel` data has 548 obervations and 14 variables and tells us
about the weight of different types of trash for a given year from years
2014 to 2022 to power the number of homes ranging from 13 to 2.9139^{4}.

The `professortrashweel` data has 95 obervations and 13 variables and
tells us about the weight of different types of trash for a given year
from years 2017 to 2022 to power the number of homes ranging from 10 to
3168.

The `gwynndatrashweel` data has 107 obervations and 11 variables and
tells us about the weight of different types of trash for a given year
from years 2021 to 2022 to power the number of homes ranging from 12 to
5179.

The `data_combine` data has 548 obervations and 15 variables and tells
us about the weight of different types of trash for a given year from
years 2014 to 2022 to power the number of homes ranging from 13 to
2.9139^{4}.

The total weight of trash collected by Professor Trash Wheel is
380.24tons and the total number of cigarette butts collected by Gwynnda
in July of 2021 is 4.739^{4}.

## Problem 3

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values; comment on the steps on the import process
and the features of the dataset.

Check whether some participants appear in only the baseline or amyloid
datasets, and comment on your findings. Combine the demographic and
biomarker datasets so that only participants who appear in both datasets
are retained, and briefly describe the resulting dataset; export the
result as a CSV to your data directory.

``` r
baseline=
  #read and clean the data 
  read_csv("./data/data_mci/MCI_baseline.csv") %>% 
  janitor::clean_names() %>% 
  #remove observations those do not meet the stated inclusion criteria 
 filter(age_at_the_onset_of_mci_missing_if_a_subject_remains_mci_free_during_the_follow_up_period != ".") %>% 
  # Ensure that sex and APOE4 carrier status are appropriate encoded
  mutate(x1_male_0_female=recode(x1_male_0_female,'1'="male",'0'="female")) %>% 
  mutate(x1_apoe4_carrier_0_apoe4_non_carrier=recode(x1_apoe4_carrier_0_apoe4_non_carrier,"1"="carrier","0"="non-carrier")) %>% 
  #change the column name
   rename("sex" = "x1_male_0_female",
          "apoe4_status"="x1_apoe4_carrier_0_apoe4_non_carrier",
          "age_at_the_onset_of_mci"="age_at_the_onset_of_mci_missing_if_a_subject_remains_mci_free_during_the_follow_up_period") %>%   rename("ID"="x1") %>% 
  #convert age from char to num
   mutate_at(vars(age_at_the_study_baseline), as.numeric) %>% 
  #remove the first row
  slice(-1)
```

    ## New names:
    ## Rows: 484 Columns: 6
    ## ── Column specification
    ## ──────────────────────────────────────────────────────── Delimiter: "," chr
    ## (6): ...1, Age at the study baseline, 1 = Male, 0 = Female, Years of edu...
    ## ℹ Use `spec()` to retrieve the full column specification for this data. ℹ
    ## Specify the column types or set `show_col_types = FALSE` to quiet this message.
    ## • `` -> `...1`

    ## Warning: There was 1 warning in `mutate()`.
    ## ℹ In argument: `age_at_the_study_baseline =
    ##   .Primitive("as.double")(age_at_the_study_baseline)`.
    ## Caused by warning:
    ## ! NAs introduced by coercion

``` r
baseline
```

    ## # A tibble: 97 × 6
    ##    ID    age_at_the_study_baseline sex    years_of_education apoe4_status
    ##    <chr>                     <dbl> <chr>  <chr>              <chr>       
    ##  1 3                          62.5 male   16                 carrier     
    ##  2 5                          66   male   16                 non-carrier 
    ##  3 7                          66.5 male   18                 non-carrier 
    ##  4 13                         63.1 male   12                 carrier     
    ##  5 14                         58.4 female 20                 non-carrier 
    ##  6 18                         67.8 male   16                 non-carrier 
    ##  7 22                         67.3 female 20                 carrier     
    ##  8 26                         64.8 female 20                 carrier     
    ##  9 30                         66.3 female 12                 non-carrier 
    ## 10 39                         68.3 female 16                 carrier     
    ## # ℹ 87 more rows
    ## # ℹ 1 more variable: age_at_the_onset_of_mci <chr>

``` r
#calculate proportion of women in the study are APOE4 carriers 
carrier <- filter(baseline, apoe4_status == "carrier")
femaleproportion <- (nrow(filter(carrier, sex=="female")) / nrow(carrier))*100
```

I import the daseline dataset and clean it by removing observations
without MCI records. There were originally 483 participants, 97 of them
have developed MCI. The average baseline age is 65.6113402. 49.1803279%
of women in the study are APOE4 carriers.
