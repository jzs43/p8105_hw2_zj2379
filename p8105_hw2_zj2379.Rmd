---
title: "p8105_hw2_zj2379"
author: "Zheshu Jiang"
date: "2023-10-02"
output: github_document
---

##Problem 1
First, clean the data in pols-month.csv. Use separate() to break up the variable mon into integer variables year, month, and day; replace month number with month name; create a president variable taking values gop and dem, and remove prez_dem and prez_gop; and remove the day variable.
```{r}
library(tidyverse)
```

```{r}
month_df = 
  tibble(
    month_num = 1:12,
    month_abb = month.abb,
    month = month.name
  )
```

Clean the data in pols-month.csv
```{r}
pols=
  read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>%
  janitor::clean_names() %>% 
  separate(mon,into=c("year","month","day"),sep="-") %>% 
  mutate_at(vars(year, month, day), as.numeric) %>% 
  mutate(month=recode(month, '01'="January" , '02'="February",'03'="March",'04'="April","05"="May","06"="June","07"="July","08"="August","09"="Septemer","10"="October","11"="November","12"="December")) %>% 
   mutate(president = recode(prez_gop, "0" = "dem", "1" = "gop", "2" = "gop")) |>
  left_join(x = _, y = month_df) %>% 
  select(year, month, everything(), -day, -starts_with("prez"))
```
Second, clean the data in snp.csv using a similar process to the above. For consistency across datasets, arrange according to year and month, and organize so that year and month are the leading columns.

```{r}
snp = 
  read_csv("./data/fivethirtyeight_datasets/snp.csv") %>% 
  janitor::clean_names() %>% 
  separate(date, into = c("month", "day", "year"), convert = TRUE) %>% 
  arrange(year, month) %>% 
  mutate(month = month.name[month]) %>% 
  select(year, month, close) 
```

Third, tidy the unemployment data so that it can be merged with the previous datasets. This process will involve switching from “wide” to “long” format; ensuring that key variables have the same name; and ensuring that key variables take the same values.

```{r clean_538_unemp}
unemployment = 
  read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
   rename(year = Year) %>% 
  pivot_longer(
    Jan:Dec, 
    names_to = "month_abb",
    values_to = "unemployment"
  ) |> 
  left_join(x = _, y = month_df) %>% 
  select(year, month, unemployment)
```
Join the datasets by merging snp into pols, and merging unemployment into the result.
```{r merge_538}
data_538 = 
  left_join(pols, snp)|>
  left_join(x = _, y = unemployment)
```

## problem 2

```{r}
library(readxl)
```

```{r}
mrtrashweel=
  read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Mr. Trash Wheel") %>%
  janitor::clean_names() %>%
  filter(if_any(everything(), ~ !is.na(.)))%>%
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  mutate_at(vars(year), as.numeric) %>% 
  drop_na(dumpster) %>% 
  add_column(type = "Mr. Trash") %>%
  select(-x15,-x16)
mrtrashweel
```

```{r}
gwynndatrashweel=
   read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Gwynnda Trash Wheel") %>% 
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  drop_na(dumpster) %>% 
  add_column(type = "Gwynnda Trash") 
```

```{r}
professortrashweel=
   read_excel("./data/202309 Trash Wheel Collection Data.xlsx", sheet="Professor Trash Wheel") %>% 
  janitor::clean_names() %>%filter(if_any(everything(), ~ !is.na(.))) %>% 
  mutate(homes_powered=(500*weight_tons)/30) %>%  
  drop_na(dumpster) %>% 
  add_column(type = "Professor Trash") 
```


```{r}
#merge three datasets
data_combine = 
  bind_rows(mrtrashweel, professortrashweel) |>
  bind_rows(x = _, y = gwynndatrashweel)
```


For each dataset, I clean the data, update the home_powered vlues, and add a new column.

The `mrtrashweel` data has `r nrow(mrtrashweel)` obervations and `r ncol(mrtrashweel)` variables and tells us about the weight of different types of trash for a given year from years 2014 to 2022 to power the number of homes ranging from `r range(mrtrashweel$homes_powered)[1]` to `r range(mrtrashweel$homes_powered)[2]` and the average number of home powered is `r mean(mrtrashweel$homes_powered)`.

The `professortrashweel` data has `r nrow(professortrashweel)` obervations and `r ncol(professortrashweel)` variables and tells us about the weight of different types of trash for a given year from years 2017 to 2022 to power the number of homes ranging from `r range(professortrashweel$homes_powered)[1]` to `r range(professortrashweel$homes_powered)[2]` and the average number of home powered is `r mean(professortrashweel$homes_powered)`.

The `gwynndatrashweel` data has `r nrow(gwynndatrashweel)` obervations and `r ncol(gwynndatrashweel)` variables and tells us about the weight of different types of trash for a given year from years 2021 to 2022 to power the number of homes ranging from `r range(gwynndatrashweel$homes_powered)[1]` to `r range(gwynndatrashweel$homes_powered)[2]` and the average number of home powered is `r mean(gwynndatrashweel$homes_powered)`.

The `data_combine` data has `r nrow(data_combine)` obervations and `r ncol(data_combine)` variables and tells us about the weight of different types of trash for a given year from years 2014 to 2022 to power the number of homes ranging from `r range(data_combine$homes_powered)[1]` to `r range(data_combine$homes_powered)[2]` and the average number of home powered is `r mean(data_combine$homes_powered)`.

The total weight of trash collected by Professor Trash Wheel is `r sum(professortrashweel$weight_tons)`tons and the total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(filter(mrtrashweel, month == "July" & year == 2021)$cigarette_butts)`.

## Problem 3

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values; comment on the steps on the import process and the features of the dataset.

Check whether some participants appear in only the baseline or amyloid datasets, and comment on your findings. Combine the demographic and biomarker datasets so that only participants who appear in both datasets are retained, and briefly describe the resulting dataset; export the result as a CSV to your data directory.

```{r}
baseline=
  read_csv("./data/data_mci/MCI_baseline.csv", skip = 1) %>% 
  janitor::clean_names() %>% 
  mutate(
    sex = recode(sex, "0" = "female", "1" = "male"),
    apoe4 = recode(apoe4, "0" = "non-apoe4 carrier", "1" = "apoe4 carrier"),
    age_at_onset = ifelse(age_at_onset == '.', NA, age_at_onset)
  ) |>
  filter(current_age < age_at_onset | is.na(age_at_onset)) 
```


I import the daseline dataset and clean it by removing observations without MCI records and the first row. There were originally 483 participants, `r nrow(baseline)` of them have developed MCI. The average baseline age is `r mean(baseline$age_at_the_study_baseline)`. `r as.integer(count(filter(baseline, sex == "female" & apoe4 == "apoe4 carrier")))/as.integer(count(filter(baseline, sex == "female")))*100`% of women in the study are APOE4 carriers.

```{r}
amyloid = read_csv("./data/data_mci/mci_amyloid.csv", skip = 1) |>
  janitor::clean_names() |>
  rename(
    id = study_id,
    time_0 = baseline
    ) |>
  pivot_longer(
    time_0:time_8, 
    names_to = "timeperiod",
    values_to = "time in years elapsed"
  ) 
```

I import the amuloid.cvs data, remove the first row, rename two columns, set time period from time_0 to time_8, and use pivot_longer to transpose data from wider to longer for better visulization. The final amyloid dataset has `r nrow(amyloid)` observations.

```{r}
# Find participants unique to the "baseline" dataset
baseline_unique=anti_join(baseline,amyloid)
nrow(baseline_unique)
# Find participants unique to the "amyloid" dataset
amyloid_unique=anti_join(amyloid, baseline)
nrow(amyloid_unique)
# Combine the datasets, retaining only participants common to both datasets
combined_data2 <- inner_join(baseline, amyloid, by = "id")
nrow(combined_data2)
```
`r nrow(baseline_unique)` participants found unique to the baseline dataset and `r nrow(amyloid_unique)` participants found unique to the amyloid dataset. `r nrow(combined_data2)` appear in both datasets.


